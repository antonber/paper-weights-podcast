<?xml version="1.0" ?>
<rss xmlns:ns0="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Paper Weights: Daily AI Research Briefing</title>
    <description>Every morning, two hosts break down the AI papers that actually matter — one explains the science, one asks where the money is. Hundreds of papers filtered down to the dozen or so that could become products, disrupt markets, or change how you build. 15 minutes. No filler.</description>
    <link>https://github.com/antonber/paper-weights-podcast</link>
    <language>en</language>
    <ns0:author>Paper Weights</ns0:author>
    <ns0:explicit>no</ns0:explicit>
    <ns0:category text="Technology"/>
    <ns0:image href="https://github.com/antonber/paper-weights-podcast/releases/download/assets/cover-art.png"/>
    <item>
      <title>Fail-Closed Alignment</title>
      <description>Today we're breaking down Fail-Closed Alignment. Alex explains the science, Maya asks where the money is. 1 papers that could change how you build.

Papers discussed:
• [00:38] Fail-Closed Alignment — https://arxiv.org/abs/2602.16977</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-21/2026-02-21-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-21/2026-02-21-podcast.mp3</guid>
      <pubDate>Sat, 21 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-21/2026-02-21-podcast.mp3" length="13084798" type="audio/mpeg"/>
      <ns0:duration>00:14:13</ns0:duration>
    </item>
    <item>
      <title>Training Large Reasoning Models Efficiently via Progressive Thought Encoding</title>
      <description>Today's episode dives deep into Training Large Reasoning Models Efficiently via Progressive Thought Encoding, along with Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents, MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks. Plus 11 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 18 papers, zero filler.

Deep Dives:
• [00:51] Training Large Reasoning Models Efficiently via Progressive Thought Encoding — https://arxiv.org/abs/2602.16839
• [02:12] Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents — https://arxiv.org/abs/2602.16943
• [03:47] MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks — https://arxiv.org/abs/2602.16313
• [05:30] Fail-Closed Alignment for Large Language Models — https://arxiv.org/abs/2602.16839
• [07:28] Phase-Aware Mixture of Experts for Agentic Reinforcement Learning — https://arxiv.org/abs/2602.17038
• [09:33] 2Mamba2Furious: Linear in Complexity, Competitive in Accuracy — https://arxiv.org/abs/2602.17363
• [11:31] NeST: Neuron Selective Tuning for LLM Safety — https://arxiv.org/abs/2602.16835

Quick Hits:
• [13:21] Narrow fine-tuning erodes safety alignment in vision-language agents — https://arxiv.org/abs/2602.16943
• Align Once, Benefit Multilingually — https://arxiv.org/abs/2602.16660
• AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks — https://arxiv.org/abs/2602.16901
• Automating Agent Hijacking via Structural Template Injection — https://arxiv.org/abs/2602.16958
• OpenSage: Self-programming Agent Generation Engine — https://arxiv.org/abs/2602.16891
• Learning Personalized Agents from Human Feedback — https://arxiv.org/abs/2602.16173
• Towards a Science of AI Agent Reliability — https://arxiv.org/abs/2602.16666
• Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability — https://arxiv.org/abs/2602.17544
• Better Think Thrice: Learning to Reason Causally with Double Counterfactual Consistency — https://arxiv.org/abs/2602.16787
• References Improve LLM Alignment in Non-Verifiable Domains — https://arxiv.org/abs/2602.16802
• Arcee Trinity Large Technical Report — https://arxiv.org/abs/2602.17445</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-20/2026-02-20-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-20/2026-02-20-podcast.mp3</guid>
      <pubDate>Fri, 20 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-20/2026-02-20-podcast.mp3" length="16085207" type="audio/mpeg"/>
      <ns0:duration>00:17:31</ns0:duration>
    </item>
    <item>
      <title>GLM-5: From Vibe Coding to Agentic Engineering</title>
      <description>Today's episode dives deep into GLM-5: From Vibe Coding to Agentic Engineering, along with The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety, Discovering Implicit Large Language Model Alignment Objectives. Plus 11 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 18 papers, zero filler.

Deep Dives:
• [01:08] GLM-5: From Vibe Coding to Agentic Engineering — https://arxiv.org/abs/2602.15763
• [02:32] The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety — https://arxiv.org/abs/2602.15799
• [04:35] Discovering Implicit Large Language Model Alignment Objectives — https://arxiv.org/abs/2602.15338
• [06:30] Prescriptive Scaling Reveals the Evolution of Language Model Capabilities — https://arxiv.org/abs/2602.15338
• [08:09] STAPO: Stabilizing RL for LLMs by Silencing Rare Spurious Tokens — https://arxiv.org/abs/2602.15620
• [10:04] Fast KV Compaction via Attention Matching — https://arxiv.org/abs/2602.16284
• [11:51] Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections — https://arxiv.org/abs/2602.15654

Quick Hits:
• [13:23] Operationalising the Superficial Alignment Hypothesis via Task Complexity — https://arxiv.org/abs/2602.15829
• Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety — https://arxiv.org/abs/2602.16660
• Unforgeable Watermarks for Language Models via Robust Signatures — https://arxiv.org/abs/2602.15323
• MoE-Spec: Expert Budgeting for Efficient Speculative Decoding — https://arxiv.org/abs/2602.16052
• ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns — https://arxiv.org/abs/2602.15521
• CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing — https://arxiv.org/abs/2602.15823
• Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents — https://arxiv.org/abs/2602.16699
• HiPER: Hierarchical RL with Explicit Credit Assignment for LLM Agents — https://arxiv.org/abs/2602.16165
• Team of Thoughts: Efficient Test-time Scaling via Orchestrated Tool Calling — https://arxiv.org/abs/2602.16485
• Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory — https://arxiv.org/abs/2602.15313
• Retrieval Collapses When AI Pollutes the Web — https://arxiv.org/abs/2602.16136</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-19/2026-02-19-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-19/2026-02-19-podcast.mp3</guid>
      <pubDate>Thu, 19 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-19/2026-02-19-podcast.mp3" length="14182832" type="audio/mpeg"/>
      <ns0:duration>00:15:25</ns0:duration>
    </item>
    <item>
      <title>ResearchGym: Evaluating Language Model Agents on Real-World AI Research</title>
      <description>Today's episode dives deep into ResearchGym: Evaluating Language Model Agents on Real-World AI Research, along with ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns, Recursive Concept Evolution: Compositional Reasoning via Dynamic Representation Geometry. Plus 11 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 18 papers, zero filler.

Deep Dives:
• [00:40] ResearchGym: Evaluating Language Model Agents on Real-World AI Research — https://arxiv.org/abs/2602.15112
• [02:06] ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns — https://arxiv.org/abs/2602.15521
• [03:33] Recursive Concept Evolution: Compositional Reasoning via Dynamic Representation Geometry — https://arxiv.org/abs/2602.15725
• [05:13] Magma: Momentum-Aligned Gradient Masking for LLM Training — https://arxiv.org/abs/2602.15322
• [06:40] Panini: Continual Learning via Generative Semantic Workspaces — https://arxiv.org/abs/2602.15156
• [08:00] Automatically Finding Reward Model Biases — https://arxiv.org/abs/2602.15222
• [09:27] ÜberWeb: A 20-Trillion-Token Multilingual Corpus — https://arxiv.org/abs/2602.15210

Quick Hits:
• [10:54] Prescriptive Scaling Reveals the Evolution of Language Model Capabilities — https://arxiv.org/abs/2602.15112
• DRTC: Identifying Critical Trace Segments in Reasoning Models — https://arxiv.org/abs/2602.15332
• Fast On-Policy Distillation from Reasoning Prefixes — https://arxiv.org/abs/2602.15260
• OpaqueToolsBench: Learning Tool Behavior Through Interaction — https://arxiv.org/abs/2602.15197
• World-Model-Augmented Web Agents with Action Correction — https://arxiv.org/abs/2602.15384
• Closing the Distribution Gap in Adversarial Training for LLMs — https://arxiv.org/abs/2602.15238
• Protecting LMs Against Unauthorized Distillation via Trace Rewriting — https://arxiv.org/abs/2602.15143
• In Agents We Trust, but Who Do Agents Trust? — https://arxiv.org/abs/2602.15456
• COMPOT: Training-Free Transformer Compression — https://arxiv.org/abs/2602.15200
• Mnemis: Dual-Route Retrieval for Long-Term LLM Memory — https://arxiv.org/abs/2602.15313
• PERSONA: Dynamic Personality Control via Activation Vector Algebra — https://arxiv.org/abs/2602.15669</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-18/2026-02-18-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-18/2026-02-18-podcast.mp3</guid>
      <pubDate>Wed, 18 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-18/2026-02-18-podcast.mp3" length="11892255" type="audio/mpeg"/>
      <ns0:duration>00:13:01</ns0:duration>
    </item>
    <item>
      <title>BFS-PO: Best-First Search for Large Reasoning Models</title>
      <description>Today's episode dives deep into BFS-PO: Best-First Search for Large Reasoning Models, along with Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models, Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens. Plus 10 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 17 papers, zero filler.

Deep Dives:
• [00:39] BFS-PO: Best-First Search for Large Reasoning Models — https://arxiv.org/abs/2602.14917
• [01:49] Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models — https://arxiv.org/abs/2602.14917
• [03:00] Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens — https://arxiv.org/abs/2602.13517
• [04:42] AMOR: Entropy-Based Metacognitive Gate for Dynamic SSM-Attention Switching — https://arxiv.org/abs/2602.13215
• [06:00] Open Rubric System: Scaling RL with Pairwise Adaptive Rubrics — https://arxiv.org/abs/2602.14069
• [07:50] OneLatent: Single-Token Compression for Visual Latent Reasoning — https://arxiv.org/abs/2602.13738
• [10:04] Information Fidelity in Tool-Using LLM Agents: A Martingale Analysis of MCP — https://arxiv.org/abs/2602.13320

Quick Hits:
• [11:38] Speculative Decoding with a Speculative Vocabulary — https://arxiv.org/abs/2602.13836
• GradMAP: Faster Layer Pruning with Gradient Metric and Projection Compensation — https://arxiv.org/abs/2602.14649
• AllMem: A Memory-centric Recipe for Efficient Long-context Modeling — https://arxiv.org/abs/2602.13680
• Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment — https://arxiv.org/abs/2602.13575
• Small Reward Models via Backward Inference — https://arxiv.org/abs/2602.13551
• Measuring and Mitigating Post-hoc Rationalization in Reverse Chain-of-Thought — https://arxiv.org/abs/2602.14469
• REMem: Reasoning with Episodic Memory in Language Agents — https://arxiv.org/abs/2602.13530
• GUI-GENESIS: Automated Synthesis of Environments with Verifiable Rewards for GUI Agent Post-Training — https://arxiv.org/abs/2602.14093
• REDSearcher: A Scalable Framework for Long-Horizon Search Agents — https://arxiv.org/abs/2602.14234
• LogitsCoder: Efficient Chain-of-Thought Path Search via Logits Preference Decoding — https://arxiv.org/abs/2602.14054</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-17/2026-02-17-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-17/2026-02-17-podcast.mp3</guid>
      <pubDate>Tue, 17 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-17/2026-02-17-podcast.mp3" length="12519063" type="audio/mpeg"/>
      <ns0:duration>00:13:35</ns0:duration>
    </item>
    <item>
      <title>Decoupling Reasoning Proposals from Decisions</title>
      <description>Today's episode dives deep into Decoupling Reasoning Proposals from Decisions, along with Cognitive Budget Allocation for Agents, The Reasoning Model Attack Surface (EXTENDED). Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 7 papers, zero filler.

Papers discussed:
• [00:51] Decoupling Reasoning Proposals from Decisions — https://arxiv.org/abs/2602.12846v1
• [02:18] Cognitive Budget Allocation for Agents — https://arxiv.org/abs/2602.12662v1
• [03:44] The Reasoning Model Attack Surface (EXTENDED)
• [06:20] Verifier-Free Reasoning Training
• [08:04] Shorter Chains of Thought Without the Accuracy Hit
• [09:39] The Diversity Illusion in Self-Play Training — https://arxiv.org/abs/2602.13103v1
• [11:14] Web Agent Training at Scale — https://arxiv.org/abs/2602.12544v1</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-16/2026-02-16-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-16/2026-02-16-podcast.mp3</guid>
      <pubDate>Mon, 16 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-16/2026-02-16-podcast.mp3" length="14115715" type="audio/mpeg"/>
      <ns0:duration>00:15:16</ns0:duration>
    </item>
    <item>
      <title>Pensieve Paradigm</title>
      <description>Today we're breaking down Pensieve Paradigm. Alex explains the science, Maya asks where the money is. 1 papers that could change how you build.

Papers discussed:
• [00:56] Pensieve Paradigm — https://arxiv.org/abs/2602.12108</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-14/2026-02-14-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-14/2026-02-14-podcast.mp3</guid>
      <pubDate>Sat, 14 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-14/2026-02-14-podcast.mp3" length="8497174" type="audio/mpeg"/>
      <ns0:duration>00:09:10</ns0:duration>
    </item>
    <item>
      <title>Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of ...</title>
      <description>Today's episode dives deep into Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs, along with Native Reasoning Models: Training Language Models to Reason on Unverifiable Data, MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling. Plus 11 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 18 papers, zero filler.

Deep Dives:
• [00:47] Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs — https://arxiv.org/abs/2602.11729v1
• [01:50] Native Reasoning Models: Training Language Models to Reason on Unverifiable Data — https://arxiv.org/abs/2602.11549v1
• [03:33] MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling — https://arxiv.org/abs/2602.11761v1
• [05:00] Extending Puzzle for Mixture-of-Experts Reasoning Models (GPT-OSS Acceleration) — https://arxiv.org/abs/2602.11549v1
• [06:35] The Pensieve Paradigm: StateLM — Stateful Language Models Mastering Their Own Context — https://arxiv.org/abs/2602.11549v1
• [08:33] Stop Unnecessary Reflection: Adaptive Reflection and Length Coordinated Penalty for LRMs — https://arxiv.org/abs/2602.12113v1
• [10:00] DICE: Diffusion Large Language Models Excel at Generating CUDA Kernels — https://arxiv.org/abs/2602.11549v1

Quick Hits:
• [11:19] ThinkRouter: Efficient Reasoning via Routing Between Latent and Discrete Spaces — https://arxiv.org/abs/2602.11683v1
• Think Longer to Explore Deeper: In-Context Exploration via Length-Incentivized RL — https://arxiv.org/abs/2602.11748v1
• PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning — https://arxiv.org/abs/2602.11683v1
• Composition-RL: Composing Verifiable Prompts for RL of LLMs — https://arxiv.org/abs/2602.12036v1
• Capability-Oriented Training Induced Alignment Risk — https://arxiv.org/abs/2602.12124v1
• DeepSight: An All-in-One LM Safety Toolkit — https://arxiv.org/abs/2602.12092v1
• Detecting RLVR Training Data via Structural Convergence of Reasoning — https://arxiv.org/abs/2602.11549v1
• Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments — https://arxiv.org/abs/2602.11964v1
• TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents — https://arxiv.org/abs/2602.11767v1
• Deep Kernel Fusion for Transformers — https://arxiv.org/abs/2602.11808v1
• PASCAL: Phase-Aware Scheduling for Serving Reasoning-based LLMs — https://arxiv.org/abs/2602.11530v1</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-13/2026-02-13-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-13/2026-02-13-podcast.mp3</guid>
      <pubDate>Fri, 13 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-13/2026-02-13-podcast.mp3" length="13708463" type="audio/mpeg"/>
      <ns0:duration>00:14:53</ns0:duration>
    </item>
    <item>
      <title>Data Repetition Beats Data Scaling</title>
      <description>Today's episode dives deep into Data Repetition Beats Data Scaling, along with Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away.. Plus 7 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 9 papers, zero filler.

Deep Dives:
• [00:42] Data Repetition Beats Data Scaling — http://arxiv.org/abs/2602.07839v1
• [02:15] Safety Recovery in Reasoning Models Is Only a Few Early Steering Steps Away. — http://arxiv.org/abs/2602.07831v1

Quick Hits:
• [12:02] Can Large Language Models Make Everyone Happy?
• On the Robustness of Knowledge Editing for Detoxification
• The Landscape of Prompt Injection Threats
• RePO: Bridging On-Policy and Off-Policy Learning
• Weight Decay Improves Language Model Plasticity
• Why Does RL Generalize Better Than SFT?
• MoEEdit: Routing-Stable Knowledge Editing for MoE LLMs</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-12/2026-02-12-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-12/2026-02-12-podcast.mp3</guid>
      <pubDate>Thu, 12 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-12/2026-02-12-podcast.mp3" length="12560905" type="audio/mpeg"/>
      <ns0:duration>00:13:35</ns0:duration>
    </item>
    <item>
      <title>The Geometry of Thinking</title>
      <description>Today's episode dives deep into The Geometry of Thinking, along with Reading the Model's Mind Before It Speaks, The Safety Trilemma. Plus 1 quick hits covering the rest of what dropped on arXiv. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 7 papers, zero filler.

Deep Dives:
• [00:40] The Geometry of Thinking
• [01:54] Reading the Model's Mind Before It Speaks
• [03:26] The Safety Trilemma
• [05:09] Finding the Point of No Return
• [06:29] The Token Efficiency Problem
• [08:47] We Finally Know Why Reasoning Works

Quick Hits:
• [10:53] Knowledge Integration Decay — https://arxiv.org/abs/2602.09517</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-11/2026-02-11-podcast-v2.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-11/2026-02-11-podcast-v2.mp3</guid>
      <pubDate>Wed, 11 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-11/2026-02-11-podcast-v2.mp3" length="11426453" type="audio/mpeg"/>
      <ns0:duration>00:12:36</ns0:duration>
    </item>
    <item>
      <title>iGRPO — Self-Feedback-Driven LLM Reasoning</title>
      <description>Today's episode dives deep into iGRPO — Self-Feedback-Driven LLM Reasoning, along with Next Concept Prediction — Beyond Token-Level Thinking, CoRefine — Confidence-Guided Self-Refinement. Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 7 papers, zero filler.

Papers discussed:
• [00:36] iGRPO — Self-Feedback-Driven LLM Reasoning — http://arxiv.org/abs/2602.09000v1
• [01:39] Next Concept Prediction — Beyond Token-Level Thinking — http://arxiv.org/abs/2602.08984v1
• [02:51] CoRefine — Confidence-Guided Self-Refinement — http://arxiv.org/abs/2602.08948v1
• [04:03] DirMoE — Dirichlet-Routed Mixture of Experts — http://arxiv.org/abs/2602.09001v1
• [05:15] InternAgent — The Robot Scientist
• [06:54] Misaligned Actions in Computer-Use Agents — http://arxiv.org/abs/2602.08995v1
• [08:24] Goal-Directedness in Language Model Agents — http://arxiv.org/abs/2602.08964v1</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-10/2026-02-10-podcast.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-10/2026-02-10-podcast.mp3</guid>
      <pubDate>Tue, 10 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-10/2026-02-10-podcast.mp3" length="13906181" type="audio/mpeg"/>
      <ns0:duration>00:15:01</ns0:duration>
    </item>
    <item>
      <title>InftyThink+ (Reasoning Efficiency)</title>
      <description>Today's episode dives deep into InftyThink+ (Reasoning Efficiency), along with Generative Meta-Model of LLM Activations (Interpretability), DAWN (Diffusion LLM Speedup). Alex breaks down the technical details while Maya asks the hard questions about what actually matters for building products and making money. 7 papers, zero filler.

Papers discussed:
• [00:00] InftyThink+ (Reasoning Efficiency)
• [00:43] Generative Meta-Model of LLM Activations (Interpretability) — https://arxiv.org/abs/2602.06964
• [02:52] DAWN (Diffusion LLM Speedup)
• [04:40] Agentic Overconfidence — https://arxiv.org/abs/2602.06948
• [06:06] Endogenous Steering Resistance — https://arxiv.org/abs/2602.06941
• [07:54] Multi-Objective Alignment Interference — https://arxiv.org/abs/2602.06869
• [09:20] Halluverse Multilingual Hallucination Benchmark — https://arxiv.org/abs/2602.06920</description>
      <link>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-09/2026-02-09-podcast-v2.mp3</link>
      <guid>https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-09/2026-02-09-podcast-v2.mp3</guid>
      <pubDate>Mon, 09 Feb 2026 09:00:00 -0600</pubDate>
      <enclosure url="https://github.com/antonber/paper-weights-podcast/releases/download/2026-02-09/2026-02-09-podcast-v2.mp3" length="10234614" type="audio/mpeg"/>
      <ns0:duration>00:12:56</ns0:duration>
    </item>
  </channel>
</rss>
